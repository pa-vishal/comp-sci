<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Analysis & Visualization</title>
    <link rel="stylesheet" href="styles/main.css">
</head>
<body>
    <header>
        <h1>Mastering Recursion</h1>
        <nav>
            <a href="index.html">Home</a>
            <a href="mindset.html">The Mindset</a>
            <a href="analysis.html" class="active">Analysis</a>
            <a href="patterns.html">Common Patterns</a>
        </nav>
    </header>

    <main>
        <section class="card">
            <h2>Visualization & Analysis: Your X-Ray Vision</h2>
            <p>To truly understand a recursive algorithm's performance, you must be able to visualize it.</p>
        </section>

        <section class="card">
            <h3>1. The Recursion Tree</h3>
            <p>This is your primary tool. Each function call is a node, and its children are the recursive calls it makes. This immediately reveals the structure and potential inefficiencies.</p>
            <p><strong>Example: `fibonacci(4)`</strong></p>
            <img src="assets/fibonacci-tree.svg" alt="Recursion tree for Fibonacci 4" class="responsive-img">
            <p>Notice the repeated computations for `fib(2)` and `fib(1)`. This is a giant clue: <strong>overlapping subproblems</strong>. This tells you that Dynamic Programming is a good optimization strategy.</p>
        </section>

        <section class="card">
            <h3>2. The Recurrence Relation</h3>
            <p>This is the mathematical formula for the time complexity, `T(n)`. It's defined as: `T(n) = (Work in one call) + T(subproblems)`.</p>
            <ul>
                <li><strong>Factorial:</strong> <code>T(n) = T(n-1) + O(1)</code></li>
                <li><strong>Fibonacci:</strong> <code>T(n) = T(n-1) + T(n-2) + O(1)</code></li>
                <li><strong>Merge Sort:</strong> <code>T(n) = 2T(n/2) + O(n)</code></li>
            </ul>
        </section>

        <section class="card">
            <h3>3. Deriving Time Complexity</h3>
            <p>The <strong>Master Theorem</strong> is a shortcut for recurrences of the form <code>T(n) = aT(n/b) + f(n)</code>. Compare <code>f(n)</code> to <code>n<sup>log<sub>b</sub>a</sup></code>.</p>
            <div class="master-cases">
                <div class="case"><strong>Case 1:</strong> If f(n) grows slower, T(n) = O(n<sup>log<sub>b</sub>a</sup>)</div>
                <div class="case"><strong>Case 2:</strong> If f(n) grows same, T(n) = O(n<sup>log<sub>b</sub>a</sup> * log n)</div>
                <div class="case"><strong>Case 3:</strong> If f(n) grows faster, T(n) = O(f(n))</div>
            </div>
            <p>For Merge Sort (`a=2, b=2, f(n)=n`), we compare `n` with `n<sup>log<sub>2</sub>2</sup> = n`. This is Case 2, so complexity is `O(n log n)`. </p>
        </section>
    </main>

    <footer>
        <p>&copy; 2023 Your Name Here. A guide for becoming an expert.</p>
    </footer>
</body>
</html>